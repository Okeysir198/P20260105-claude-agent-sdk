# Prompt Version Registry
# Tracks all prompt versions with metadata and metrics
#
# Usage:
#   - Add new versions under 'versions:' with description and status
#   - Update 'defaults:' to set which version is active per prompt
#   - Track evaluation metrics under 'metrics:' for data-driven decisions
#
# Status values: draft | testing | active | deprecated | archived

versions:
  v1:
    description: "Baseline professional prompts"
    created: "{date}"
    status: active
  # v2:
  #   description: "Improved version with explicit triggers"
  #   created: "{date}"
  #   status: testing
  #   parent: v1

# Active version for each prompt (used at runtime)
defaults:
  # prompt01_{agent_id}: v1
  # prompt02_{agent_id}: v1

# Evaluation metrics per prompt/version (updated by eval runner)
metrics:
  # prompt01_{agent_id}:
  #   v1:
  #     evaluations: 0
  #     success_rate: null
  #     avg_turn_count: null
  #     avg_response_length: null
  #     tool_call_accuracy: null
  #   v2:
  #     evaluations: 0
  #     success_rate: null
  #     avg_turn_count: null
  #     avg_response_length: null
  #     tool_call_accuracy: null

# A/B test tracking (optional)
# ab_tests:
#   test_001:
#     prompt: prompt01_{agent_id}
#     control: v1
#     variants: [v1a, v1b]
#     start_date: "{date}"
#     end_date: null
#     status: running
#     sample_size_target: 100
#     current_results:
#       v1:  {evaluations: 0, success_rate: null}
#       v1a: {evaluations: 0, success_rate: null}
#       v1b: {evaluations: 0, success_rate: null}
