{
  "evalId": "eval-qD9-2025-12-29T09:33:42",
  "results": {
    "version": 3,
    "timestamp": "2025-12-29T09:33:42.655Z",
    "prompts": [
      {
        "raw": "{{test_case_definition}}",
        "label": "{{test_case_definition}}",
        "id": "be0b371a391d572dd8e3ef281d730b373bcde36dafc842251727974f06beadf6",
        "provider": "v2",
        "metrics": {
          "score": 1.5,
          "testPassCount": 1,
          "testFailCount": 1,
          "testErrorCount": 0,
          "assertPassCount": 3,
          "assertFailCount": 1,
          "totalLatencyMs": 8604,
          "tokenUsage": {
            "prompt": 0,
            "completion": 0,
            "cached": 0,
            "total": 0,
            "numRequests": 2,
            "completionDetails": {
              "reasoning": 0,
              "acceptedPrediction": 0,
              "rejectedPrediction": 0
            },
            "assertions": {
              "total": 671,
              "prompt": 269,
              "completion": 39,
              "cached": 363,
              "numRequests": 0,
              "completionDetails": {
                "reasoning": 0,
                "acceptedPrediction": 0,
                "rejectedPrediction": 0
              }
            }
          },
          "namedScores": {},
          "namedScoresCount": {},
          "cost": 0
        }
      }
    ],
    "results": [
      {
        "cost": 0,
        "gradingResult": {
          "pass": true,
          "score": 1,
          "reason": "All assertions passed",
          "namedScores": {},
          "tokensUsed": {
            "total": 363,
            "prompt": 0,
            "completion": 0,
            "cached": 363,
            "numRequests": 0
          },
          "componentResults": [
            {
              "pass": true,
              "score": 1,
              "reason": "Assertion passed",
              "assertion": {
                "type": "contains",
                "value": "[TOOL:confirm_person]"
              }
            },
            {
              "assertion": {
                "type": "llm-rubric",
                "value": "The agent response should be professional and polite. It should acknowledge the person and smoothly transition to the next step without being aggressive or intimidating."
              },
              "pass": true,
              "score": 1,
              "reason": "The agent greets the user politely, acknowledges them, explains the purpose of recording the call, and requests ID confirmation in a non-aggressive way. The transitions between steps are smooth and professional.",
              "tokensUsed": {
                "total": 363,
                "prompt": 0,
                "completion": 0,
                "cached": 363,
                "numRequests": 0,
                "completionDetails": {
                  "reasoning": 0,
                  "acceptedPrediction": 0,
                  "rejectedPrediction": 0
                }
              }
            }
          ]
        },
        "id": "30621387-5ad8-4cb1-b7d5-03fd02335749",
        "latencyMs": 1145,
        "namedScores": {},
        "prompt": {
          "raw": "Name: INT-001: Person confirms identity\nType: single_turn\n\nUser: Yes, speaking\n\nAssert:\n  - contains_function_call: confirm_person\n  - llm_rubric: The agent response should be professional and polite. It should acknowledge the person and smoothly transition to the next step without being aggressive or intimidating.",
          "label": "{{test_case_definition}}"
        },
        "promptId": "be0b371a391d572dd8e3ef281d730b373bcde36dafc842251727974f06beadf6",
        "promptIdx": 0,
        "provider": {
          "id": "file://promptfoo/provider.py",
          "label": "v2"
        },
        "response": {
          "output": "Agent: DFSDFSDFSD: Hi there, this is calling from . I hope I'm not catching you at a bad time. Am I speaking with John Smith?\n\nUser: Yes, speaking\nAgent: Please note that this call is recorded for quality and security purposes. To ensure I am speaking to the right person, please confirm your full ID number.\n  -> Tool: confirm_person({})\n  <- Result: \n  -> Handoff: introduction_agent -> verification_agent\n\n[TOOL:confirm_person]",
          "metadata": {
            "test_name": "INT-001: Person confirms identity",
            "turns": 2,
            "duration_ms": 5487.7,
            "score": 0.5,
            "passed": 1,
            "failed": 1,
            "stop_reason": "completed",
            "tool_names": [
              "confirm_person"
            ]
          },
          "tool_calls": [
            {
              "name": "confirm_person",
              "arguments": {}
            }
          ],
          "cached": true
        },
        "score": 1,
        "success": true,
        "testCase": {
          "description": "INT-001: Person confirms identity",
          "vars": {
            "test_case_definition": "Name: INT-001: Person confirms identity\nType: single_turn\n\nUser: Yes, speaking\n\nAssert:\n  - contains_function_call: confirm_person\n  - llm_rubric: The agent response should be professional and polite. It should acknowledge the person and smoothly transition to the next step without being aggressive or intimidating."
          },
          "assert": [
            {
              "type": "contains",
              "value": "[TOOL:confirm_person]"
            },
            {
              "type": "llm-rubric",
              "value": "The agent response should be professional and polite. It should acknowledge the person and smoothly transition to the next step without being aggressive or intimidating."
            }
          ],
          "metadata": {
            "tags": [
              "unit",
              "introduction",
              "happy-path"
            ],
            "source_file": "agent01_introduction.yaml",
            "agent_id": "debt_collection",
            "sub_agent_id": "introduction",
            "test_data": "  full_name: John Smith\n  user_id: U12345\n  username: jsmith001\n  id_number: 8501015800087\n  birth_date: 1985-01-15\n  email: john.smith@example.com\n  contact_number: 0821234567\n  outstanding_amount: 2500.0\n  overdue_days: 45\n  script_type: ratio1_inflow\n  account_status: active"
          },
          "options": {
            "timeout": 60000
          }
        },
        "testIdx": 0,
        "vars": {
          "test_case_definition": "Name: INT-001: Person confirms identity\nType: single_turn\n\nUser: Yes, speaking\n\nAssert:\n  - contains_function_call: confirm_person\n  - llm_rubric: The agent response should be professional and polite. It should acknowledge the person and smoothly transition to the next step without being aggressive or intimidating."
        },
        "metadata": {
          "tags": [
            "unit",
            "introduction",
            "happy-path"
          ],
          "source_file": "agent01_introduction.yaml",
          "agent_id": "debt_collection",
          "sub_agent_id": "introduction",
          "test_data": "  full_name: John Smith\n  user_id: U12345\n  username: jsmith001\n  id_number: 8501015800087\n  birth_date: 1985-01-15\n  email: john.smith@example.com\n  contact_number: 0821234567\n  outstanding_amount: 2500.0\n  overdue_days: 45\n  script_type: ratio1_inflow\n  account_status: active",
          "test_name": "INT-001: Person confirms identity",
          "turns": 2,
          "duration_ms": 5487.7,
          "score": 0.5,
          "passed": 1,
          "failed": 1,
          "stop_reason": "completed",
          "tool_names": [
            "confirm_person"
          ],
          "_promptfooFileMetadata": {}
        },
        "failureReason": 0
      },
      {
        "cost": 0,
        "error": "Expected output to contain \"[TOOL:handle_wrong_person]\"",
        "gradingResult": {
          "pass": false,
          "score": 0.5,
          "reason": "Expected output to contain \"[TOOL:handle_wrong_person]\"",
          "namedScores": {},
          "tokensUsed": {
            "total": 308,
            "prompt": 269,
            "completion": 39,
            "cached": 0,
            "numRequests": 0
          },
          "componentResults": [
            {
              "pass": false,
              "score": 0,
              "reason": "Expected output to contain \"[TOOL:handle_wrong_person]\"",
              "assertion": {
                "type": "contains",
                "value": "[TOOL:handle_wrong_person]"
              }
            },
            {
              "assertion": {
                "type": "llm-rubric",
                "value": "The agent should apologize for the inconvenience, be polite, and end the call gracefully without pressuring the person."
              },
              "pass": true,
              "score": 1,
              "reason": "The agent apologized for the mix-up, was polite, and ended the call gracefully without pressuring the person.",
              "tokensUsed": {
                "total": 308,
                "prompt": 269,
                "completion": 39,
                "cached": 0,
                "numRequests": 0,
                "completionDetails": {
                  "reasoning": 0,
                  "acceptedPrediction": 0,
                  "rejectedPrediction": 0
                }
              }
            }
          ]
        },
        "id": "1b551e06-770f-45fc-a554-22c30e1448df",
        "latencyMs": 7459,
        "namedScores": {},
        "prompt": {
          "raw": "Name: INT-002: Wrong number\nType: single_turn\n\nUser: Sorry, wrong number. I don't know anyone by that name.\n\nAssert:\n  - contains_function_call: handle_wrong_person\n  - llm_rubric: The agent should apologize for the inconvenience, be polite, and end the call gracefully without pressuring the person.",
          "label": "{{test_case_definition}}"
        },
        "promptId": "be0b371a391d572dd8e3ef281d730b373bcde36dafc842251727974f06beadf6",
        "promptIdx": 0,
        "provider": {
          "id": "file://promptfoo/provider.py",
          "label": "v2"
        },
        "response": {
          "output": "Agent: DFSDFSDFSD: Hi there, this is calling from . I hope I'm not catching you at a bad time. Am I speaking with John Smith?\n\nUser: Sorry, wrong number. I don't know anyone by that name.\nAgent: DFSDFSDFSD: I apologize for the mix-up. Thank you for your time.\n",
          "metadata": {
            "test_name": "INT-002: Wrong number",
            "turns": 2,
            "duration_ms": 6236.36,
            "score": 0,
            "passed": 0,
            "failed": 2,
            "stop_reason": "completed",
            "tool_names": []
          },
          "tool_calls": [],
          "cached": false
        },
        "score": 0.5,
        "success": false,
        "testCase": {
          "description": "INT-002: Wrong number",
          "vars": {
            "test_case_definition": "Name: INT-002: Wrong number\nType: single_turn\n\nUser: Sorry, wrong number. I don't know anyone by that name.\n\nAssert:\n  - contains_function_call: handle_wrong_person\n  - llm_rubric: The agent should apologize for the inconvenience, be polite, and end the call gracefully without pressuring the person."
          },
          "assert": [
            {
              "type": "contains",
              "value": "[TOOL:handle_wrong_person]"
            },
            {
              "type": "llm-rubric",
              "value": "The agent should apologize for the inconvenience, be polite, and end the call gracefully without pressuring the person."
            }
          ],
          "metadata": {
            "tags": [
              "unit",
              "introduction"
            ],
            "source_file": "agent01_introduction.yaml",
            "agent_id": "debt_collection",
            "sub_agent_id": "introduction",
            "test_data": "  full_name: John Smith\n  user_id: U12345\n  username: jsmith001\n  id_number: 8501015800087\n  birth_date: 1985-01-15\n  email: john.smith@example.com\n  contact_number: 0821234567\n  outstanding_amount: 2500.0\n  overdue_days: 45\n  script_type: ratio1_inflow\n  account_status: active"
          },
          "options": {
            "timeout": 60000
          }
        },
        "testIdx": 1,
        "vars": {
          "test_case_definition": "Name: INT-002: Wrong number\nType: single_turn\n\nUser: Sorry, wrong number. I don't know anyone by that name.\n\nAssert:\n  - contains_function_call: handle_wrong_person\n  - llm_rubric: The agent should apologize for the inconvenience, be polite, and end the call gracefully without pressuring the person."
        },
        "metadata": {
          "tags": [
            "unit",
            "introduction"
          ],
          "source_file": "agent01_introduction.yaml",
          "agent_id": "debt_collection",
          "sub_agent_id": "introduction",
          "test_data": "  full_name: John Smith\n  user_id: U12345\n  username: jsmith001\n  id_number: 8501015800087\n  birth_date: 1985-01-15\n  email: john.smith@example.com\n  contact_number: 0821234567\n  outstanding_amount: 2500.0\n  overdue_days: 45\n  script_type: ratio1_inflow\n  account_status: active",
          "test_name": "INT-002: Wrong number",
          "turns": 2,
          "duration_ms": 6236.36,
          "score": 0,
          "passed": 0,
          "failed": 2,
          "stop_reason": "completed",
          "tool_names": [],
          "_promptfooFileMetadata": {}
        },
        "failureReason": 1
      }
    ],
    "stats": {
      "successes": 1,
      "failures": 1,
      "errors": 0,
      "tokenUsage": {
        "prompt": 0,
        "completion": 0,
        "cached": 0,
        "total": 0,
        "numRequests": 2,
        "completionDetails": {
          "reasoning": 0,
          "acceptedPrediction": 0,
          "rejectedPrediction": 0
        },
        "assertions": {
          "total": 671,
          "prompt": 269,
          "completion": 39,
          "cached": 363,
          "numRequests": 0,
          "completionDetails": {
            "reasoning": 0,
            "acceptedPrediction": 0,
            "rejectedPrediction": 0
          }
        }
      }
    }
  },
  "config": {
    "tags": {},
    "description": "LiveKit Voice Agent Evaluation",
    "prompts": [
      "{{test_case_definition}}"
    ],
    "providers": [
      {
        "id": "file://promptfoo/provider.py",
        "label": "v2",
        "config": {
          "version": "v2",
          "description": "Empathetic approach - softer tone",
          "model": "gpt-4o-mini",
          "temperature": 0,
          "sub_agents": {
            "introduction": {
              "prompt_version": "v2"
            },
            "negotiation": {
              "prompt_version": "v2"
            },
            "closing": {
              "prompt_version": "v2"
            }
          },
          "prompts": {
            "[introduction]": "prompts/prompt01_introduction_v2.yaml",
            "[verification]": "prompts/prompt02_verification.yaml",
            "[negotiation]": "prompts/prompt03_negotiation_v2.yaml",
            "[payment]": "prompts/prompt04_payment.yaml",
            "[closing]": "prompts/prompt05_closing_v2.yaml"
          }
        }
      }
    ],
    "tests": [
      {
        "description": "INT-001: Person confirms identity",
        "vars": {
          "test_case_definition": "Name: INT-001: Person confirms identity\nType: single_turn\n\nUser: Yes, speaking\n\nAssert:\n  - contains_function_call: confirm_person\n  - llm_rubric: The agent response should be professional and polite. It should acknowledge the person and smoothly transition to the next step without being aggressive or intimidating."
        },
        "assert": [
          {
            "type": "contains",
            "value": "[TOOL:confirm_person]"
          },
          {
            "type": "llm-rubric",
            "value": "The agent response should be professional and polite. It should acknowledge the person and smoothly transition to the next step without being aggressive or intimidating."
          }
        ],
        "metadata": {
          "tags": [
            "unit",
            "introduction",
            "happy-path"
          ],
          "source_file": "agent01_introduction.yaml",
          "agent_id": "debt_collection",
          "sub_agent_id": "introduction",
          "test_data": "  full_name: John Smith\n  user_id: U12345\n  username: jsmith001\n  id_number: 8501015800087\n  birth_date: 1985-01-15\n  email: john.smith@example.com\n  contact_number: 0821234567\n  outstanding_amount: 2500.0\n  overdue_days: 45\n  script_type: ratio1_inflow\n  account_status: active"
        }
      },
      {
        "description": "INT-002: Wrong number",
        "vars": {
          "test_case_definition": "Name: INT-002: Wrong number\nType: single_turn\n\nUser: Sorry, wrong number. I don't know anyone by that name.\n\nAssert:\n  - contains_function_call: handle_wrong_person\n  - llm_rubric: The agent should apologize for the inconvenience, be polite, and end the call gracefully without pressuring the person."
        },
        "assert": [
          {
            "type": "contains",
            "value": "[TOOL:handle_wrong_person]"
          },
          {
            "type": "llm-rubric",
            "value": "The agent should apologize for the inconvenience, be polite, and end the call gracefully without pressuring the person."
          }
        ],
        "metadata": {
          "tags": [
            "unit",
            "introduction"
          ],
          "source_file": "agent01_introduction.yaml",
          "agent_id": "debt_collection",
          "sub_agent_id": "introduction",
          "test_data": "  full_name: John Smith\n  user_id: U12345\n  username: jsmith001\n  id_number: 8501015800087\n  birth_date: 1985-01-15\n  email: john.smith@example.com\n  contact_number: 0821234567\n  outstanding_amount: 2500.0\n  overdue_days: 45\n  script_type: ratio1_inflow\n  account_status: active"
        }
      }
    ],
    "scenarios": [],
    "env": {},
    "defaultTest": {
      "options": {
        "timeout": 60000
      },
      "vars": {},
      "assert": [],
      "metadata": {}
    },
    "outputPath": [
      "/home/ct-admin/Documents/Langgraph/P20251204-livekit-voice-agents/livekit-backend/agents/debt_collection/eval/results.json"
    ],
    "extensions": [],
    "metadata": {},
    "evaluateOptions": {}
  },
  "shareableUrl": null,
  "metadata": {
    "promptfooVersion": "0.119.13",
    "nodeVersion": "v20.17.0",
    "platform": "linux",
    "arch": "x64",
    "exportedAt": "2025-12-29T09:33:51.113Z",
    "evaluationCreatedAt": "2025-12-29T09:33:42.655Z"
  }
}